{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rwV9QH_S29Y"
   },
   "source": [
    "# Ejercicio de multinomialNB\n",
    "\n",
    "En el caso anterior, para medir la cantidad de artículos clasiicados correctamente se utilizó el mismo subconjunto del dataset que se utilizó para entrenar.\n",
    "\n",
    "Esta medida no es una medida del todo útil, ya que lo que interesa de un clasificador es su capacidad de clasificación de datos que no fueron utilizados para entrenar. Es por eso que se pide, para el clasificador entrenado con el subconjunto de training, cual es el porcentaje de artículos del subconjunto de testing clasificados correctamente. Comparar con el porcentaje anterior y explicar las diferencias.\n",
    "\n",
    "Para este ejercicio se puede utilizar el paquete multinomialNB que se encuentra dentro de naive-bayes en el paquete sklearn.\n",
    "\n",
    "** Importante: para aplicar count vectorizer al dataset de testing sin redefinir el vocabulario, se debe usar el método transform, ya que fit y fit_transform recalculan el vocabulario. **\n",
    "\n",
    "Se puede encontrar mas información del dataset en:\n",
    "\n",
    "http://scikit-learn.org/stable/datasets/twenty_newsgroups.html#newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5AFvPlfS6OO"
   },
   "source": [
    "# Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIvOl9vCU9uC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "articulos_filtrados = []\n",
    "with open ('art_filt.txt', 'rb') as fp:\n",
    "    articulos_filtrados = pickle.load(fp)\n",
    "    \n",
    "\n",
    "div = int(len(articulos_filtrados)*0.9)\n",
    "\n",
    "train = articulos_filtrados[:div]\n",
    "test = articulos_filtrados[div:]\n",
    "\n",
    "len(articulos_filtrados) # chequeamos que articulos filtrados y train+test tengan mismo numero de elementos\n",
    "print(len(train)+len(test))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(max_df=0.8,min_df=100)\n",
    "X_train_data= count_vect.fit_transform(train) #Aprende el vocabulario y le asigna un código a cada palabra\n",
    "X_test_data = count_vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.08833922261485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha = 10)\n",
    "clf.fit(X_train_data.toarray(), twenty_train[\"target\"][:div])\n",
    "\n",
    "predict = np.array(clf.predict(X_test_data))\n",
    "porc=sum(predict==np.array(twenty_train[\"target\"][div:]))/len(test)\n",
    "print(porc*100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Naive Bayes para TNG.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "redes2 (py 3.6)",
   "language": "python",
   "name": "redes2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
